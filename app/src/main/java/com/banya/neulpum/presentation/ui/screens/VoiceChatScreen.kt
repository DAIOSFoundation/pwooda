package com.banya.neulpum.presentation.ui.screens

import android.Manifest
import android.content.Context
import android.content.pm.PackageManager
import androidx.compose.foundation.background
import androidx.compose.foundation.layout.*
import androidx.compose.foundation.shape.CircleShape
import androidx.compose.foundation.shape.RoundedCornerShape
import androidx.compose.material.icons.Icons
import androidx.compose.material.icons.filled.Mic
import androidx.compose.material.icons.filled.Stop
import androidx.compose.material3.*
import androidx.compose.runtime.*
import androidx.compose.runtime.DisposableEffect
import androidx.compose.ui.Alignment
import androidx.compose.ui.Modifier
import androidx.compose.ui.graphics.Color
import androidx.compose.ui.graphics.Brush
import androidx.compose.ui.platform.LocalContext
import androidx.compose.ui.text.font.FontWeight
import androidx.compose.ui.unit.dp
import androidx.compose.ui.unit.sp
import androidx.core.content.ContextCompat
import com.banya.neulpum.data.remote.GoogleSpeechService
import com.banya.neulpum.presentation.ui.components.EqualizerBars
import com.banya.neulpum.presentation.ui.components.EqualizerCenterReactive
import com.banya.neulpum.data.remote.VoiceWebSocketClient
import androidx.media3.common.AudioAttributes
import androidx.media3.common.C
import androidx.media3.common.PlaybackException
import androidx.media3.common.Player
import androidx.media3.exoplayer.ExoPlayer
import kotlinx.coroutines.delay
import kotlinx.coroutines.GlobalScope
import kotlinx.coroutines.launch
import com.banya.neulpum.presentation.ui.components.voice.VoiceCenterOverlay
import com.banya.neulpum.presentation.ui.components.voice.VoiceMicButton
import com.banya.neulpum.presentation.ui.components.voice.CircularParticleView
import com.banya.neulpum.utils.PermissionHelper
import com.banya.neulpum.utils.rememberPermissionHelper
import com.banya.neulpum.presentation.ui.components.MicrophonePermissionDialog
import androidx.compose.ui.viewinterop.AndroidView
import kotlin.random.Random
import android.media.audiofx.Visualizer
import kotlin.math.sqrt

@OptIn(ExperimentalMaterial3Api::class)
@Composable
fun VoiceChatScreen(
    paddingValues: PaddingValues = PaddingValues(0.dp),
    conversationId: String? = null,
    onConversationCreated: (String) -> Unit = {}
) {
    val context = LocalContext.current
    val permissionHelper = rememberPermissionHelper()
    
    var isRecording by remember { mutableStateOf(false) }
    var recordingTime by remember { mutableStateOf(0) }
    var partialText by remember { mutableStateOf("") }
    var speechService by remember { mutableStateOf<GoogleSpeechService?>(null) }
    
        // ì›Œí¬í”Œë¡œìš° ìƒíƒœ
        var currentWorkflowStep by remember { mutableStateOf("") }
        var isProcessing by remember { mutableStateOf(false) }
    
    var hasMicrophonePermission by remember {
        mutableStateOf(
            permissionHelper.isPermissionGranted(PermissionHelper.RECORD_AUDIO_PERMISSION)
        )
    }
    
    var showPermissionDialog by remember { mutableStateOf(false) }
    
    // í™”ë©´ì´ í‘œì‹œë  ë•Œë§ˆë‹¤ ê¶Œí•œ ìƒíƒœë¥¼ ë‹¤ì‹œ í™•ì¸
    LaunchedEffect(Unit) {
        hasMicrophonePermission = permissionHelper.isPermissionGranted(PermissionHelper.RECORD_AUDIO_PERMISSION)
    }
    
    
    var wsClient by remember { mutableStateOf<VoiceWebSocketClient?>(null) }
    var isWsConnected by remember { mutableStateOf(false) }
    var player by remember { mutableStateOf<ExoPlayer?>(null) }
    var isPlaying by remember { mutableStateOf(false) }
    var isAwaitingResponse by remember { mutableStateOf(false) }
    var audioLevel by remember { mutableStateOf(0f) }
    var visualizer by remember { mutableStateOf<Visualizer?>(null) }
    var pendingText by remember { mutableStateOf<String?>(null) }
    var doneReceived by remember { mutableStateOf(false) }
    var fallbackScheduled by remember { mutableStateOf(false) }
    var lastAudioFormat by remember { mutableStateOf<String?>(null) }
    var isWsConnecting by remember { mutableStateOf(false) }
    val mainHandler = remember { androidx.core.os.HandlerCompat.createAsync(android.os.Looper.getMainLooper()) }
    var lastRecognizedText by remember { mutableStateOf<String?>(null) }
    // ìŒì„± ì±„íŒ…ë„ ì¼ë°˜ ì±„íŒ…ê³¼ ë™ì¼í•˜ê²Œ conversationId ì‚¬ìš©
    var currentConversationId by remember { mutableStateOf(conversationId) }
    
    
    // ë…¹ìŒ ì‹œê°„ ì—…ë°ì´íŠ¸
    LaunchedEffect(isRecording) {
        if (isRecording) {
            while (isRecording) {
                delay(1000)
                recordingTime++
            }
        } else {
            recordingTime = 0
        }
    }
    
    // ìŒì„± ì¸ì‹ ì„œë¹„ìŠ¤ ë° WebSocket ì´ˆê¸°í™”
    LaunchedEffect(Unit) {
        speechService = GoogleSpeechService(context, "YOUR_GOOGLE_API_KEY")
        // WebSocket ì—°ê²° ì„¤ì •
        val prefs = context.getSharedPreferences("auth_prefs", Context.MODE_PRIVATE)
        val access = prefs.getString("access_token", null)
        val orgKey = prefs.getString("organization_api_key", null)
        val base = com.banya.neulpum.di.AppConfig.BASE_HOST
        val wsScheme = if (base.startsWith("https")) "wss" else "ws"
        val wsUrl = base.replaceFirst(Regex("^https?"), wsScheme) + "/ws/voice"
        // mainHandler ë° debugToastëŠ” Composable ìŠ¤ì½”í”„ì—ì„œ rememberë¡œ ê³µìœ ë¨
        player = ExoPlayer.Builder(context).build().apply {
            val attrs = AudioAttributes.Builder()
                .setUsage(C.USAGE_MEDIA)
                .setContentType(C.AUDIO_CONTENT_TYPE_SPEECH)
                .build()
            setAudioAttributes(attrs, true)
            volume = 1f
            addListener(object : Player.Listener {
                override fun onPlaybackStateChanged(playbackState: Int) {
                    if (playbackState == Player.STATE_ENDED) {
                        mainHandler.post {
                            isPlaying = false
                            audioLevel = 0f
                            try { visualizer?.release() } catch (_: Exception) {}
                            visualizer = null
                        }
                    }
                }
                override fun onPlayerError(error: PlaybackException) {
                    mainHandler.post {
                        isPlaying = false
                        audioLevel = 0f
                        try { visualizer?.release() } catch (_: Exception) {}
                        visualizer = null
                    }
                }
                override fun onIsPlayingChanged(isPlayingNow: Boolean) {
                    mainHandler.post { isPlaying = isPlayingNow }
                }
            })
        }
        wsClient = VoiceWebSocketClient(wsUrl, access, orgKey, object: VoiceWebSocketClient.Listener {
            override fun onOpen() {
                isWsConnected = true
                isWsConnecting = false
                // ì—°ê²° ì§€ì—° ì‹œ ë³´ë‚¸ í…ìŠ¤íŠ¸ë¥¼ ì¦‰ì‹œ ì „ì†¡
                val p = pendingText
                if (!p.isNullOrBlank()) {
                    wsClient?.sendText(p, currentConversationId) // ê¸°ì¡´ ëŒ€í™” ì‚¬ìš© (ì¼ë°˜ ì±„íŒ…ê³¼ ë™ì¼)
                    pendingText = null
                }
                
            }
            override fun onTtsChunk(bytes: ByteArray, format: String?) {
                // ê¸°ì¡´ ë°©ì‹ (í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€) - ë²„í¼ë§ ì—†ì´ ì¦‰ì‹œ ì¬ìƒ
                GlobalScope.launch {
                    try {
                        lastAudioFormat = format
                        
                        if (bytes.isNotEmpty()) {
                            val ext = if (format == "wav") ".wav" else ".mp3"
                            val cache = java.io.File.createTempFile("tts_", ext, context.cacheDir)
                            cache.writeBytes(bytes)
                            val mediaItem = androidx.media3.common.MediaItem.fromUri(android.net.Uri.fromFile(cache))
                            mainHandler.post {
                                player?.stop()
                                player?.clearMediaItems()
                                player?.setMediaItem(mediaItem)
                                player?.prepare()
                                player?.play()
                                isPlaying = true
                                isAwaitingResponse = false
                                doneReceived = true
                                fallbackScheduled = false
                            }
                        }
                    } catch (_: Exception) {}
                }
            }
            override fun onTtsChunkStream(bytes: ByteArray, format: String?, chunkIndex: Int, isFinal: Boolean) {
                // ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë””ì˜¤ ì²­í¬ ì²˜ë¦¬ - ì¦‰ì‹œ ì¬ìƒ
                GlobalScope.launch {
                    try {
                        lastAudioFormat = format
                        
                        if (bytes.isNotEmpty()) {
                            val ext = if (format == "wav") ".wav" else ".mp3"
                            val tempFile = java.io.File.createTempFile("tts_stream_${chunkIndex}_", ext, context.cacheDir)
                            tempFile.writeBytes(bytes)
                            val mediaItem = androidx.media3.common.MediaItem.fromUri(android.net.Uri.fromFile(tempFile))
                            
                            mainHandler.post {
                                if (chunkIndex == 0) {
                                    // ì²« ì²­í¬ëŠ” ì¦‰ì‹œ ì¬ìƒ ì‹œì‘
                                    player?.stop()
                                    player?.clearMediaItems()
                                    player?.setMediaItem(mediaItem)
                                    player?.prepare()
                                    player?.play()
                                    isPlaying = true
                                    isAwaitingResponse = false
                                } else {
                                    // í›„ì† ì²­í¬ëŠ” íì— ì¶”ê°€
                                    player?.addMediaItem(mediaItem)
                                }
                                
                                // ìµœì¢… ì²­í¬ì¸ ê²½ìš° ìƒíƒœ ì •ë¦¬
                                if (isFinal) {
                                    doneReceived = true
                                    fallbackScheduled = false
                                    isAwaitingResponse = false
                                }
                            }
                        }
                        
                    } catch (e: Exception) {
                        println("VoiceChatScreen: Error in onTtsChunkStream: $e")
                    }
                }
            }
                override fun onDone() {
                    println("VoiceChatScreen: onDone called")
                    android.util.Log.d("VoiceChatScreen", "onDone called")
                    // onDoneì€ ì´ì œ ìƒíƒœ ì´ˆê¸°í™”ë§Œ ë‹´ë‹¹ (ì¬ìƒì€ onTtsChunkì—ì„œ ì²˜ë¦¬)
                    doneReceived = true
                    fallbackScheduled = false
                    isAwaitingResponse = false
                    
                    // ì›Œí¬í”Œë¡œìš° ì™„ë£Œ ìƒíƒœë¡œ ì—…ë°ì´íŠ¸
                    currentWorkflowStep = ""
                    isProcessing = false
                    println("VoiceChatScreen: Workflow completed - step cleared, processing=false")
                    android.util.Log.d("VoiceChatScreen", "Workflow completed - step cleared, processing=false")
                    
                    // ë³´ì´ìŠ¤ ì±„íŒ… ì™„ë£Œ ì‹œ ëŒ€í™” ìƒì„± ì½œë°± í˜¸ì¶œ (ëŒ€í™”ê°€ ìƒì„±ë˜ì—ˆë‹¤ë©´)
                    if (currentConversationId != null) {
                        onConversationCreated(currentConversationId!!)
                    }
                }
            override fun onError(error: String) {
                isAwaitingResponse = false
                isWsConnecting = false
            }
            override fun onLog(stage: String, message: String) {
                println("VoiceChatScreen: onLog received - Stage: $stage, Message: $message")
                android.util.Log.d("VoiceChatScreen", "onLog received - Stage: $stage, Message: $message")
                // ì›Œí¬í”Œë¡œìš° ë‹¨ê³„ ì—…ë°ì´íŠ¸ - ë” ì•Œì•„ë³´ê¸° ì‰½ê²Œ
                when (stage) {
                    "plan", "planner" -> {
                        currentWorkflowStep = "ğŸ¤” ìƒê° ì¤‘..."
                        isProcessing = true
                    }
                    "tool_executor" -> {
                        currentWorkflowStep = "ğŸ”§ ì‘ì—… ì¤‘..."
                        isProcessing = true
                    }
                    "summarize" -> {
                        currentWorkflowStep = "âœï¸ ë‹µë³€ ì‘ì„± ì¤‘..."
                        isProcessing = true
                    }
                    "tts" -> {
                        currentWorkflowStep = "ğŸµ ìŒì„± ë³€í™˜ ì¤‘..."
                        isProcessing = true
                    }
                    "done" -> {
                        currentWorkflowStep = ""
                        isProcessing = false
                    }
                    else -> {
                        currentWorkflowStep = when (stage) {
                            "rag" -> "ğŸ“š ì •ë³´ ê²€ìƒ‰ ì¤‘..."
                            "mcp" -> "ğŸ”— ë„êµ¬ ì‹¤í–‰ ì¤‘..."
                            "api" -> "ğŸŒ API í˜¸ì¶œ ì¤‘..."
                            "db" -> "ğŸ’¾ ë°ì´í„° ì²˜ë¦¬ ì¤‘..."
                            else -> "âš™ï¸ ì²˜ë¦¬ ì¤‘..."
                        }
                        isProcessing = true
                    }
                }
                println("VoiceChatScreen: Updated workflow step: $currentWorkflowStep, isProcessing: $isProcessing")
                android.util.Log.d("VoiceChatScreen", "Updated workflow step: $currentWorkflowStep, isProcessing: $isProcessing")
            }
            override fun onClose(code: Int, reason: String) {
                isWsConnected = false
                isAwaitingResponse = false
                isWsConnecting = false
                
            }
                override fun onConversationCreated(conversationId: String) {
                    currentConversationId = conversationId
                    onConversationCreated(conversationId)
                }
        })
        // ì—°ê²°ì€ ì¦‰ì‹œ í•˜ì§€ ì•ŠìŒ. ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆŒë €ì„ ë•Œ í•„ìš” ì‹œ ì—°ê²°.
    }

    DisposableEffect(Unit) {
        onDispose {
            try { wsClient?.close() } catch (_: Exception) {}
            try { player?.release() } catch (_: Exception) {}
        }
    }
    
    Box(
        modifier = Modifier
            .fillMaxSize()
            .background(Color.White)
    ) {
        // í™”ë ¤í•œ íŒŒí‹°í´ ì´í€„ë¼ì´ì € - ì›Œí¬í”Œë¡œìš° ì•„ë˜ 15dpì— ë°°ì¹˜
        Box(
            modifier = Modifier
                .fillMaxSize()
                .padding(paddingValues),
            contentAlignment = Alignment.TopCenter
        ) {
            // ì›Œí¬í”Œë¡œìš° ì•„ë˜ 15dpì— ë°°ì¹˜
            Box(
                modifier = Modifier
                    .fillMaxWidth()
                    .offset(y = if (currentWorkflowStep.isNotEmpty()) 80.dp else 40.dp), // ì›Œí¬í”Œë¡œìš°ê°€ ìˆìœ¼ë©´ 80dp, ì—†ìœ¼ë©´ 40dp
                contentAlignment = Alignment.Center
            ) {
                // í™”ë ¤í•œ íŒŒí‹°í´ ì´í€„ë¼ì´ì €
                AndroidView(
                    factory = { ctx ->
                        CircularParticleView(ctx).apply { 
                            setBackgroundColor(android.graphics.Color.TRANSPARENT)
                            startVisualizing() 
                        }
                    },
                    update = { view ->
                        if (isRecording || isPlaying) {
                            view.startVisualizing()
                            // ìµœì í™”ëœ FFT ë°ì´í„° ìƒì„± - ìºì‹œëœ ê³„ì‚° ì‚¬ìš©
                            val fftData = ByteArray(64) { i ->
                                val baseLevel = (audioLevel * 60).toInt()
                                val wave = (kotlin.math.sin(i * 0.3) * 20).toInt()
                                (baseLevel + wave).coerceIn(0, 127).toByte()
                            }
                            view.setFftData(fftData)
                        } else {
                            view.startVisualizing()
                            // ëŒ€ê¸° ìƒíƒœ - ê°„ë‹¨í•œ ì• ë‹ˆë©”ì´ì…˜
                            val fftData = ByteArray(64) { i ->
                                val idle = (kotlin.math.sin(i * 0.2) * 10 + 20).toInt()
                                idle.coerceIn(0, 127).toByte()
                            }
                            view.setFftData(fftData)
                        }
                    },
                    modifier = Modifier
                        .size(280.dp) // ì¡°ê¸ˆ ì‘ê²Œ
                        .background(Color.Transparent)
                )
            }
        }
        
        // ì›Œí¬í”Œë¡œìš° í‘œì‹œê¸° - í–„ë²„ê±°ë°”+ì œëª©ì—ì„œ 15dp ì•„ë˜ (ì˜ˆì˜ê²Œ ê¾¸ë¯¸ê¸°)
        if (currentWorkflowStep.isNotEmpty()) {
            Box(
                modifier = Modifier
                    .fillMaxSize()
                    .padding(paddingValues),
                contentAlignment = Alignment.TopCenter
            ) {
                Row(
                    modifier = Modifier
                        .fillMaxWidth()
                        .padding(horizontal = 16.dp, vertical = 8.dp)
                        .offset(y = 15.dp), // í–„ë²„ê±°ë°”+ì œëª©ì—ì„œ 15dp ì•„ë˜
                    verticalAlignment = Alignment.CenterVertically,
                    horizontalArrangement = Arrangement.Center
                ) {
                    // ê·¸ë¼ë°ì´ì…˜ ì›í˜• ë¡œë”©
                    Box(
                        modifier = Modifier
                            .size(20.dp)
                            .background(
                                brush = Brush.radialGradient(
                                    colors = listOf(
                                        Color(0xFF10A37F).copy(alpha = 0.8f),
                                        Color(0xFF10A37F).copy(alpha = 0.3f)
                                    )
                                ),
                                shape = CircleShape
                            ),
                        contentAlignment = Alignment.Center
                    ) {
                        CircularProgressIndicator(
                            modifier = Modifier.size(16.dp),
                            color = Color.White,
                            strokeWidth = 2.dp
                        )
                    }
                    Spacer(modifier = Modifier.width(12.dp))
                    Text(
                        text = currentWorkflowStep,
                        color = Color(0xFF10A37F),
                        fontSize = 15.sp,
                        fontWeight = FontWeight.SemiBold,
                        letterSpacing = 0.5.sp
                    )
                }
            }
        }
        // í•˜ë‹¨ ì˜ì—­(íŒ¨ë”© í¬í•¨) UI - ë°°ê²½ ì œê±°í•˜ì—¬ ì¤‘ì•™ ì˜¤ë²„ë ˆì´ê°€ ë³´ì´ë„ë¡
        Box(
            modifier = Modifier
                .fillMaxSize()
                .padding(paddingValues)
        ) {
            // ì „ì†¡(ë…¹ìŒ) ì¤‘ì¼ ë•Œ ë²„íŠ¼ ìœ„ ì‘ì€ ì´í€„ë¼ì´ì €
            if (isRecording) {
                Column(
                    modifier = Modifier
                        .fillMaxWidth()
                        .align(Alignment.BottomCenter)
                        .padding(bottom = 120.dp),
                    horizontalAlignment = Alignment.CenterHorizontally
                ) {
                    
                    EqualizerBars(active = true, barColor = Color(0xFF10A37F))
                    Spacer(modifier = Modifier.height(8.dp))
                }
            }

            // ìŒì„± ë…¹ìŒ FAB (í•˜ë‹¨ ì¤‘ì•™)
            VoiceMicButton(
                isRecording = isRecording,
                paddingValues = paddingValues,
                onToggle = {
                if (isRecording) {
                    isRecording = false
                    speechService?.cleanup()
                } else {
                    if (hasMicrophonePermission) {
                        // ì†Œì¼“ì´ ë¯¸ì—°ê²° ìƒíƒœì´ë©´ ìš°ì„  ì—°ê²° ì‹œë„
                        if (!isWsConnected && !isWsConnecting) {
                            isWsConnecting = true
                            try { wsClient?.connect() } catch (_: Exception) { isWsConnecting = false }
                        }
                        // ìƒˆ ë…¹ìŒ ì‹œì‘ ì‹œ ê¸°ì¡´ ìµœì¢… í…ìŠ¤íŠ¸ëŠ” ìˆ¨ê¹€
                        lastRecognizedText = null
                        isRecording = true
                        
                        // ë³´ì´ìŠ¤ ì±„íŒ… ì‹œì‘ ì‹œì—ëŠ” ìƒˆë¡œìš´ ëŒ€í™”ë¥¼ ìƒì„±í•˜ì§€ ì•ŠìŒ
                        // ì„œë²„ì—ì„œ conversation_created ì´ë²¤íŠ¸ë¥¼ ë°›ì„ ë•Œë§Œ onConversationCreated í˜¸ì¶œ
                        partialText = ""
                        // ë³´ì´ìŠ¤ ìš”ì•½ í…ìŠ¤íŠ¸ ì´ˆê¸°í™” ì œê±°
                        speechService?.startSpeechRecognition(
                            onPartialResult = { text ->
                                partialText = text
                            },
                            onFinalResult = { text ->
                                isRecording = false
                                partialText = ""
                                lastRecognizedText = text
                                if (text.isNotEmpty()) {
                                    // ìƒˆ ìš”ì²­ ì‹œì‘ ì‹œ ì´ì „ ì¬ìƒ ìƒíƒœ ì™„ì „ ì´ˆê¸°í™”
                                    try { player?.stop() } catch (_: Exception) {}
                                    try { player?.clearMediaItems() } catch (_: Exception) {}
                                    isPlaying = false
                                    audioLevel = 0f
                                    try { visualizer?.release() } catch (_: Exception) {}
                                    visualizer = null
                                    // ìƒíƒœ ë³€ìˆ˜ë“¤ ì™„ì „ ì´ˆê¸°í™”
                                    doneReceived = false
                                    fallbackScheduled = false
                                    isAwaitingResponse = true
                                    if (isWsConnected) {
                                        wsClient?.sendText(text, currentConversationId) // ê¸°ì¡´ ëŒ€í™” ì‚¬ìš© (ì¼ë°˜ ì±„íŒ…ê³¼ ë™ì¼)
                                    } else {
                                        pendingText = text
                                    }
                                }
                            },
                            onError = { _ ->
                                isRecording = false
                                partialText = ""
                                isAwaitingResponse = false
                            }
                        )
                    } else {
                        // ë§ˆì´í¬ ê¶Œí•œì´ ì—†ëŠ” ê²½ìš° ê¶Œí•œ ìš”ì²­ ë‹¤ì´ì–¼ë¡œê·¸ í‘œì‹œ
                        showPermissionDialog = true
                    }
                }
                },
                modifier = Modifier
                    .align(Alignment.BottomCenter)
            )

            // ë§ˆì§€ë§‰ ìŒì„± ì¸ì‹ ê²°ê³¼ í…ìŠ¤íŠ¸ (í•˜ë‹¨ ê³ ì • í‘œì‹œ)
            if (!lastRecognizedText.isNullOrBlank()) {
                Row(
                    modifier = Modifier
                        .align(Alignment.BottomCenter)
                        .padding(bottom = 120.dp)
                ) {
                    Surface(
                        shape = RoundedCornerShape(16.dp),
                        color = Color(0xFFF7F7F8)
                    ) {
                        Text(
                            text = lastRecognizedText ?: "",
                            color = Color.Black,
                            fontSize = 16.sp,
                            modifier = Modifier.padding(horizontal = 16.dp, vertical = 10.dp)
                        )
                    }
                }
            }
        }
    }

    // ì˜¤ë””ì˜¤ ë ˆë²¨ ì‹œê°í™”: ìµœì í™”ëœ Visualizer ì‚¬ìš©
    LaunchedEffect(isPlaying) {
        if (isPlaying) {
            // ì„¸ì…˜ ID ëŒ€ê¸° ì‹œê°„ ë‹¨ì¶•
            repeat(5) {
                if (player?.audioSessionId != C.AUDIO_SESSION_ID_UNSET) return@repeat
                delay(20)
            }
            val sessionId = player?.audioSessionId ?: C.AUDIO_SESSION_ID_UNSET
            if (sessionId != C.AUDIO_SESSION_ID_UNSET) {
                try {
                    visualizer = Visualizer(sessionId).apply {
                        captureSize = Visualizer.getCaptureSizeRange()[0] // ìµœì†Œ í¬ê¸° ì‚¬ìš©
                        setDataCaptureListener(object : Visualizer.OnDataCaptureListener {
                            override fun onWaveFormDataCapture(v: Visualizer?, bytes: ByteArray?, samplingRate: Int) {
                                if (bytes == null) return
                                // ìµœì í™”ëœ RMS ê³„ì‚°
                                var sum = 0f
                                val len = bytes.size
                                for (i in 0 until len step 4) { // 4ë°° ìƒ˜í”Œë§ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ
                                    val b = bytes[i]
                                    val fb = (b.toInt() and 0xFF) - 128
                                    sum += (fb * fb)
                                }
                                val rms = sqrt(sum / (len / 4)) / 128f
                                audioLevel = rms.coerceIn(0f, 1f)
                            }
                            override fun onFftDataCapture(v: Visualizer?, bytes: ByteArray?, samplingRate: Int) { }
                        }, Visualizer.getMaxCaptureRate() / 4, true, false) // ìº¡ì²˜ ë ˆì´íŠ¸ ê°ì†Œ
                        enabled = true
                    }
                } catch (_: Exception) {
                    // í´ë°± ì• ë‹ˆë©”ì´ì…˜ ê°„ì†Œí™”
                    while (isPlaying) {
                        audioLevel = 0.4f + Random.nextFloat() * 0.4f
                        delay(100) // ì—…ë°ì´íŠ¸ ê°„ê²© ì¦ê°€
                    }
                    audioLevel = 0f
                }
            } else {
                // í´ë°± ì• ë‹ˆë©”ì´ì…˜ ê°„ì†Œí™”
                while (isPlaying) {
                    audioLevel = 0.4f + Random.nextFloat() * 0.4f
                    delay(100) // ì—…ë°ì´íŠ¸ ê°„ê²© ì¦ê°€
                }
                audioLevel = 0f
            }
        } else {
            audioLevel = 0f
        }
    }

    DisposableEffect(Unit) {
        onDispose {
            try { visualizer?.release() } catch (_: Exception) {}
            visualizer = null
        }
    }
    
    // ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­ ë‹¤ì´ì–¼ë¡œê·¸
    if (showPermissionDialog) {
        MicrophonePermissionDialog(
            onConfirm = {
                showPermissionDialog = false
                permissionHelper.openAppSettings()
            },
            onDismiss = {
                showPermissionDialog = false
            }
        )
    }
    
}

